{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34eaa816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import pickle \n",
    "import glob\n",
    "from scipy import stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea868db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_p_tests(res, alpha = 0.05):\n",
    "    # ipdb.set_trace()\n",
    "    version_pattern = r'v?_'\n",
    "    gamma_pattern = 'G_\\d+\\.\\d+'\n",
    "    res['version'] = res['exp'].apply(lambda x: re.split(version_pattern, x)[0])\n",
    "    res['param'] = res['exp'].apply(lambda x: re.findall(gamma_pattern, x)[0])\n",
    "    res = res.groupby('param').agg({'norm_diversity_p': list, 'perc_LT_p': list}).reset_index()\n",
    "    res['#tests'] = res['perc_LT_p'].apply(len)\n",
    "    res['significant'] = res[['#tests', 'perc_LT_p']].apply(lambda x: bonferoni_significant(x, 'perc_LT_p'), axis=1)\n",
    "\n",
    "    return res \n",
    "   \n",
    "def run_p_tests(df1, df2, metric):\n",
    "    stat, p_val = stats.ttest_ind(df1[metric].values, df2[metric].values)\n",
    "    return p_val\n",
    "\n",
    "def run_wilcox(df1, df2, metric): \n",
    "    stat, p_val = stats.wilcoxon(df1[metric].values, df2[metric].values)\n",
    "    return p_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d565c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_t_test(dataset, gamma_r, gamma_b, mode): \n",
    "    prefix = f'/home/mila/r/rebecca.salganik/scratch/PinSAGE_experiments/FULL_RUNS/{dataset}/'\n",
    "    suffix = 'log10_popcat_fairness_breakdown_by_pid.pkl'\n",
    "    if mode == 'perf': \n",
    "        suffix = 'performance_breakdown_by_pid.pkl'\n",
    "    r_p = f'{prefix}REDRESS/v1_G_{gamma_r}_A_0.01_B_0.0/redress/{suffix}'\n",
    "    ps_p = f'{prefix}REDRESS/v1_G_{gamma_r}_A_0.01_B_0.0/utility/{suffix}'\n",
    "    b_p = f'{prefix}BOOST/boost2/v1_G_{gamma_b}_A_0.01/redress/{suffix}'\n",
    "   \n",
    "\n",
    "    r_df = pickle.load(open(r_p, \"rb\")).astype(float)\n",
    "    b_df = pickle.load(open(b_p, \"rb\")).astype(float)\n",
    "    ps_df = pickle.load(open(ps_p, \"rb\")).astype(float)\n",
    "    \n",
    "    metrics = [c for c in r_df.columns if 'pid' not in c]\n",
    "    \n",
    "    p_vals_redress_vs_ps = [float(run_p_tests(r_df, ps_df, m)) for m in metrics]\n",
    "    p_vals_boost_vs_ps = [float(run_p_tests(b_df, ps_df, m)) for m in metrics]\n",
    "    p_vals_boost_vs_redress = [float(run_p_tests(b_df, r_df, m)) for m in metrics]\n",
    "    \n",
    "\n",
    "    wil_redress_vs_ps = [float(run_wilcox(r_df, ps_df, m)) for m in metrics]\n",
    "    wil_boost_vs_ps = [float(run_wilcox(b_df, ps_df, m)) for m in metrics]\n",
    "    wil_boost_vs_redress = [float(run_wilcox(b_df, r_df, m)) for m in metrics]\n",
    "    \n",
    "    \n",
    "    t_test = pd.DataFrame(\n",
    "        [p_vals_redress_vs_ps, p_vals_boost_vs_ps, p_vals_boost_vs_redress], \n",
    "        columns=metrics, index=['redress_vs_ps', 'boost_vs_ps', 'boost_vs_redress'])\n",
    "\n",
    "    wilcox_test = pd.DataFrame(\n",
    "        [wil_redress_vs_ps, wil_boost_vs_ps, wil_boost_vs_redress], \n",
    "        columns=metrics, index=['redress_vs_ps', 'boost_vs_ps', 'boost_vs_redress']).astype(float)\n",
    "    \n",
    "    return t_test, wilcox_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed0fdaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_precision</th>\n",
       "      <th>competition_ndcg</th>\n",
       "      <th>artist_prec</th>\n",
       "      <th>norm_diversity</th>\n",
       "      <th>sound_homogeneity</th>\n",
       "      <th>perc_LT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>redress_vs_ps</th>\n",
       "      <td>2.241879e-04</td>\n",
       "      <td>1.733327e-04</td>\n",
       "      <td>0.141660</td>\n",
       "      <td>1.837484e-12</td>\n",
       "      <td>4.423948e-42</td>\n",
       "      <td>0.047167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boost_vs_ps</th>\n",
       "      <td>4.408083e-16</td>\n",
       "      <td>1.768725e-19</td>\n",
       "      <td>0.727897</td>\n",
       "      <td>1.168816e-29</td>\n",
       "      <td>3.751961e-61</td>\n",
       "      <td>0.000596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boost_vs_redress</th>\n",
       "      <td>5.505001e-09</td>\n",
       "      <td>1.794279e-09</td>\n",
       "      <td>0.094062</td>\n",
       "      <td>8.243730e-11</td>\n",
       "      <td>1.126384e-12</td>\n",
       "      <td>0.196477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   r_precision  competition_ndcg  artist_prec  norm_diversity  \\\n",
       "redress_vs_ps     2.241879e-04      1.733327e-04     0.141660    1.837484e-12   \n",
       "boost_vs_ps       4.408083e-16      1.768725e-19     0.727897    1.168816e-29   \n",
       "boost_vs_redress  5.505001e-09      1.794279e-09     0.094062    8.243730e-11   \n",
       "\n",
       "                  sound_homogeneity   perc_LT  \n",
       "redress_vs_ps          4.423948e-42  0.047167  \n",
       "boost_vs_ps            3.751961e-61  0.000596  \n",
       "boost_vs_redress       1.126384e-12  0.196477  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_t_df,fair_w_df =  run_t_test('MPD_Subset', '0.5', '0.5', 'fair')\n",
    "\n",
    "perf_t_df,perf_w_df = run_t_test('MPD_Subset', '0.5', '0.5', 'perf')\n",
    "\n",
    "t_df = perf_t_df.join(fair_t_df) #.apply(lambda x: np.round(x,10))\n",
    "w_df = perf_w_df.join(fair_w_df) #.apply(lambda x: np.round(x,10))\n",
    "\n",
    "\n",
    "w_df\n",
    "\n",
    "\n",
    "t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "932fa3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_precision</th>\n",
       "      <th>competition_ndcg</th>\n",
       "      <th>artist_prec</th>\n",
       "      <th>norm_diversity</th>\n",
       "      <th>sound_homogeneity</th>\n",
       "      <th>perc_LT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>redress_vs_ps</th>\n",
       "      <td>5.960803e-02</td>\n",
       "      <td>1.989518e-03</td>\n",
       "      <td>1.230002e-01</td>\n",
       "      <td>1.766603e-10</td>\n",
       "      <td>0.314695</td>\n",
       "      <td>1.618156e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boost_vs_ps</th>\n",
       "      <td>5.696989e-08</td>\n",
       "      <td>1.179627e-15</td>\n",
       "      <td>1.914129e-07</td>\n",
       "      <td>1.112495e-34</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>2.477700e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boost_vs_redress</th>\n",
       "      <td>2.824536e-05</td>\n",
       "      <td>2.549566e-08</td>\n",
       "      <td>7.331554e-04</td>\n",
       "      <td>1.887246e-13</td>\n",
       "      <td>0.034670</td>\n",
       "      <td>5.192154e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   r_precision  competition_ndcg   artist_prec  \\\n",
       "redress_vs_ps     5.960803e-02      1.989518e-03  1.230002e-01   \n",
       "boost_vs_ps       5.696989e-08      1.179627e-15  1.914129e-07   \n",
       "boost_vs_redress  2.824536e-05      2.549566e-08  7.331554e-04   \n",
       "\n",
       "                  norm_diversity  sound_homogeneity       perc_LT  \n",
       "redress_vs_ps       1.766603e-10           0.314695  1.618156e-01  \n",
       "boost_vs_ps         1.112495e-34           0.001408  2.477700e-11  \n",
       "boost_vs_redress    1.887246e-13           0.034670  5.192154e-08  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_t_df,fair_w_df =  run_t_test('LFM_Subset', '0.2', '0.6', 'fair')\n",
    "\n",
    "perf_t_df,perf_w_df = run_t_test('LFM_Subset', '0.2', '0.6', 'perf')\n",
    "\n",
    "t_df = perf_t_df.join(fair_t_df) #.apply(lambda x: np.round(x,10))\n",
    "w_df = perf_w_df.join(fair_w_df)#.apply(lambda x: np.round(x,10))\n",
    "\n",
    "\n",
    "w_df\n",
    "\n",
    "t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a739d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08731909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00022418794101332552"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_df = pickle.load(open('/home/mila/r/rebecca.salganik/scratch/PinSAGE_experiments/FULL_RUNS/MPD_Subset/REDRESS/v1_G_0.5_A_0.01_B_0.0/redress/performance_breakdown_by_pid.pkl', \"rb\"))\n",
    "\n",
    "\n",
    "u_df = pickle.load(open('/home/mila/r/rebecca.salganik/scratch/PinSAGE_experiments/FULL_RUNS/MPD_Subset/REDRESS/v1_G_0.5_A_0.01_B_0.0/utility/performance_breakdown_by_pid.pkl', \"rb\"))\n",
    "\n",
    "\n",
    "metrics = [c for c in r_df.columns if 'pid' not in c]\n",
    "    \n",
    "    \n",
    "metrics\n",
    "\n",
    "run_p_tests(r_df , u_df, 'r_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e09ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca162969",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p_vals_redress_vs_ps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mp_vals_redress_vs_ps\u001b[49m, wil_redress_vs_ps\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p_vals_redress_vs_ps' is not defined"
     ]
    }
   ],
   "source": [
    "p_vals_redress_vs_ps, wil_redress_vs_ps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c869b1e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p_vals_boost_vs_ps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mp_vals_boost_vs_ps\u001b[49m, wil_boost_vs_ps\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p_vals_boost_vs_ps' is not defined"
     ]
    }
   ],
   "source": [
    "p_vals_boost_vs_ps, wil_boost_vs_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45672359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'norm_diversity': 8.243730183460495e-11,\n",
       "  'sound_homogeneity': 1.1263840419174975e-12,\n",
       "  'perc_LT': 0.19647656540206895},\n",
       " {'norm_diversity': 2.0534705827850006e-15,\n",
       "  'sound_homogeneity': 8.267798584515514e-18,\n",
       "  'perc_LT': 0.0045003864973730216})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_vals_boost_vs_redress, wil_boost_vs_redress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2f04372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_diversity</th>\n",
       "      <th>sound_homogeneity</th>\n",
       "      <th>perc_LT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boost vs redress</th>\n",
       "      <td>2.053471e-15</td>\n",
       "      <td>8.267799e-18</td>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  norm_diversity  sound_homogeneity  perc_LT\n",
       "boost vs redress    2.053471e-15       8.267799e-18   0.0045"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e653e26a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl8.2",
   "language": "python",
   "name": "dgl8.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
